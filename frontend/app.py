import streamlit as st
import numpy as np
import requests
import base64
import time
from PIL import Image
import io
import cv2
import av
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, RTCConfiguration

API_URL = "http://127.0.0.1:8000/predict/"

st.set_page_config(page_title="PhÃ¢n loáº¡i Ä‘á»™ chÃ­n trÃ¡i mÃ­t", page_icon="ğŸˆ", layout="wide")
st.title("ğŸˆ Nháº­n dáº¡ng & phÃ¢n loáº¡i Ä‘á»™ chÃ­n trÃ¡i mÃ­t (YOLOv8)")
st.write("á»¨ng dá»¥ng YOLOv8 â€“ há»— trá»£ nhiá»u model vÃ  nguá»“n áº£nh (file, URL, hoáº·c webcam).")

# --- Session State ---
for key, default in {
    "uploaded_file": None,
    "image_url": "",
    "last_source": None,
    "analysis_result": None,
}.items():
    if key not in st.session_state:
        st.session_state[key] = default

def reset_analysis():
    st.session_state.analysis_result = None

# --- Chá»n model ---
model_choice = st.selectbox("ğŸ” Chá»n model YOLOv8:", ["YOLOv8n", "YOLOv8s"], index=1)

# --- Tabs: upload / URL / webcam ---
st.markdown("### ğŸ–¼ï¸ Chá»n nguá»“n áº£nh:")
upload_tab, url_tab, cam_tab = st.tabs(["ğŸ“ Táº£i áº£nh lÃªn", "ğŸŒ DÃ¡n URL áº£nh", "ğŸ“· Webcam real-time"])

# ===================================
# ğŸ“ Upload
# ===================================
with upload_tab:
    uploaded_file = st.file_uploader("Chá»n áº£nh tá»« mÃ¡y tÃ­nh", type=["jpg", "jpeg", "png"])
    if uploaded_file is not None:
        if st.session_state.uploaded_file != uploaded_file:
            st.session_state.uploaded_file = uploaded_file
            st.session_state.image_url = ""
            st.session_state.last_source = "upload"
            reset_analysis()

# ===================================
# ğŸŒ URL
# ===================================
with url_tab:
    url_input = st.text_input("Nháº­p URL áº£nh trá»±c tuyáº¿n", value=st.session_state.image_url)
    if url_input and url_input != st.session_state.image_url:
        st.session_state.image_url = url_input
        st.session_state.uploaded_file = None
        st.session_state.last_source = "url"
        reset_analysis()

# ===================================
# ğŸ“· WEBCAM
# ===================================
with cam_tab:
    st.info("ğŸ“¸ Nháº­n dáº¡ng real-time tá»« webcam. Hiá»ƒn thá»‹ FPS & Ä‘á»™ trá»… infer (ms).")

    # âœ… ThÃªm cÃ´ng táº¯c cháº¿ Ä‘á»™ giáº£m Ä‘á»™ trá»…
    low_latency = st.checkbox("âš¡ Báº­t Low Latency Mode (tÄƒng tá»‘c, giáº£m cháº¥t lÆ°á»£ng)", value=False)

    class VideoProcessor(VideoProcessorBase):
        def __init__(self):
            self.fps = 0
            self.prev_time = 0
            self.latency_ms = 0

        def recv(self, frame):
            start_time = time.time()

            img = frame.to_ndarray(format="bgr24")

            # Náº¿u báº­t cháº¿ Ä‘á»™ giáº£m Ä‘á»™ trá»… â†’ resize áº£nh nhá» láº¡i
            if low_latency:
                img = cv2.resize(img, (480, 360))

            # MÃ£ hÃ³a gá»­i Ä‘áº¿n backend
            _, img_encoded = cv2.imencode(".jpg", img)
            files = {"file": ("frame.jpg", img_encoded.tobytes(), "image/jpeg")}
            data = {"model_name": model_choice}

            try:
                response = requests.post(API_URL, files=files, data=data, timeout=5)
                if response.status_code == 200:
                    resp_json = response.json()
                    img_bytes = base64.b64decode(resp_json["image"])
                    img_np = cv2.imdecode(np.frombuffer(img_bytes, np.uint8), cv2.IMREAD_COLOR)
                else:
                    img_np = img
            except Exception:
                img_np = img  # fallback khi máº¥t káº¿t ná»‘i

            # TÃ­nh FPS vÃ  Ä‘á»™ trá»…
            now = time.time()
            self.latency_ms = (now - start_time) * 1000
            self.fps = 1 / (now - self.prev_time) if self.prev_time else 0
            self.prev_time = now

            # Hiá»ƒn thá»‹ FPS, Latency, Model, Mode
            color = (0, 255, 0) if not low_latency else (255, 200, 0)
            cv2.putText(img_np, f"FPS: {self.fps:.1f}", (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)
            cv2.putText(img_np, f"Latency: {self.latency_ms:.0f} ms", (10, 60),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2)
            cv2.putText(img_np, f"Model: {model_choice}", (10, 90),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
            cv2.putText(img_np, f"Mode: {'Low Latency' if low_latency else 'Normal'}",
                        (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)

            return av.VideoFrame.from_ndarray(img_np, format="bgr24")

    rtc_config = RTCConfiguration({"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]})
    webrtc_streamer(
        key="jackfruit-detect",
        video_processor_factory=VideoProcessor,
        rtc_configuration=rtc_config,
        media_stream_constraints={"video": True, "audio": False},
    )

# ===================================
# ğŸ–¼ï¸ Hiá»ƒn thá»‹ preview áº£nh tÄ©nh
# ===================================
if st.session_state.last_source == "upload" and st.session_state.uploaded_file:
    image = Image.open(st.session_state.uploaded_file)
    st.image(image, caption="áº¢nh táº£i lÃªn", use_container_width=True)
elif st.session_state.last_source == "url" and st.session_state.image_url:
    st.image(st.session_state.image_url, caption="áº¢nh tá»« URL", use_container_width=True)

# ===================================
# ğŸš€ PhÃ¢n tÃ­ch áº£nh (upload / URL)
# ===================================
if st.button("ğŸš€ PhÃ¢n tÃ­ch áº£nh"):
    if not st.session_state.uploaded_file and not st.session_state.image_url:
        st.warning("Vui lÃ²ng táº£i áº£nh hoáº·c nháº­p URL há»£p lá»‡.")
    else:
        with st.spinner("Äang xá»­ lÃ½..."):
            files = {"file": st.session_state.uploaded_file.getvalue()} if st.session_state.uploaded_file else None
            data = {"model_name": model_choice, "image_url": st.session_state.image_url}
            try:
                response = requests.post(API_URL, files=files, data=data, timeout=30)
            except Exception as e:
                st.error(f"Lá»—i khi gá»­i yÃªu cáº§u: {e}")
                st.stop()

        if response.status_code == 200:
            data = response.json()
            if "error" in data:
                st.error(data["error"])
            else:
                st.session_state.analysis_result = data
        else:
            st.error(f"Lá»—i káº¿t ná»‘i API ({response.status_code})")

# ===================================
# ğŸ“Š Hiá»ƒn thá»‹ káº¿t quáº£
# ===================================
if st.session_state.analysis_result:
    data = st.session_state.analysis_result
    img_str = data["image"]
    pred_img = Image.open(io.BytesIO(base64.b64decode(img_str)))

    col1, col2 = st.columns(2)
    with col1:
        if st.session_state.last_source == "upload" and st.session_state.uploaded_file:
            st.image(Image.open(st.session_state.uploaded_file), caption="áº¢nh gá»‘c", use_container_width=True)
        elif st.session_state.last_source == "url" and st.session_state.image_url:
            st.image(st.session_state.image_url, caption="áº¢nh gá»‘c", use_container_width=True)
    with col2:
        st.image(pred_img, caption=f"Káº¿t quáº£ ({data['model_used']})", use_container_width=True)

    st.subheader("ğŸ“Š Káº¿t quáº£ phÃ¢n loáº¡i:")
    for p in data["predictions"]:
        st.write(f"ğŸ”¸ **{p['label']}** â€“ Äá»™ tin cáº­y: {p['confidence']*100:.1f}%")
